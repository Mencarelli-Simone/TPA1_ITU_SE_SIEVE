{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import display\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from ITUtils import country_conflicts_finder\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "# show all columns\n",
    "pd.set_option('display.max_rows', None)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pick a country and import the conflicts\n",
    "adm = 'G'\n",
    "file = 'conflicts_summary_condensed.csv'\n",
    "filepath = os.path.join('.', 'adm_conflicts', adm, file)\n",
    "df = pd.read_csv(filepath, low_memory=False)\n",
    "display(df)\n",
    "print(df.columns)"
   ],
   "id": "2c76d1b42bf60dbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# logic, if the entries are identical for each pair, then keep only the second one of the pair if the overlap is 100%"
   ],
   "id": "e9ea596af4ac4a21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# steps:\n",
    "# find the uhf100 subset of the dataframe where the string 'UHF' is contained in the column 'TPA-1 Beam', and the string '100.0%' is contained in the column 'Overlap (worst case)', use this dataframe for following  \n",
    "# divide the dataframe in sub dataframes where the columns Network, Beam, and Overlap (worst case) are identical\n",
    "# for every pair in pairs check in every sub dataframe if both the strings are contained, if so add the 9.5 kHz one to a discarded dataframe\n",
    "# merge back the dataframe and return the simplified and discarded dataframes"
   ],
   "id": "12bbf3ac8ae78526",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f244f48faa9372"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def simplify_uhf_conflicts(df):\n",
    "    # Return two empty DataFrames if input is empty\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    pairs = [\n",
    "        ['UHFUP fc=401.96MHz BW=9.5kHz', 'UHFUP fc=401.96MHz BW=19.8kHz'],\n",
    "        ['UHFDN fc=401.96MHz BW=9.5kHz', 'UHFDN fc=401.96MHz BW=19.8kHz'],\n",
    "        ['UHFUP fc=401.90MHz BW=9.5kHz', 'UHFUP fc=401.90MHz BW=19.8kHz'],\n",
    "        ['UHFDN fc=401.90MHz BW=9.5kHz', 'UHFDN fc=401.90MHz BW=19.8kHz'],\n",
    "    ]\n",
    "    # Step 1: Filter for only rows where 'UHF' in 'TPA-1 Beam' and '100.0%' in Overlap\n",
    "    uhf100 = df[\n",
    "        df['TPA-1 Beam'].astype(str).str.contains('UHF', na=False) &\n",
    "        df['Overlap (worst case)'].astype(str).str.contains('100.0%', na=False)\n",
    "        ].copy()\n",
    "\n",
    "    # Step 2: Create a unique group identifier based on Network, Beam, and Overlap\n",
    "    uhf100['group_id'] = (\n",
    "            uhf100['Network'].astype(str) + '__' +\n",
    "            uhf100['Beam'].astype(str) + '__' +\n",
    "            uhf100['Overlap (worst case)'].astype(str)\n",
    "    )\n",
    "\n",
    "    # Step 3: For each group, check if both pair entries exist, and mark 9.5kHz one for discarding\n",
    "    discard_rows = []\n",
    "    grouped = uhf100.groupby('group_id')\n",
    "\n",
    "    for group_id, subdf in grouped:\n",
    "        tpa_beams = subdf['TPA-1 Beam'].tolist()\n",
    "        for low, high in pairs:\n",
    "            if low in tpa_beams and high in tpa_beams:\n",
    "                discard_row = subdf[subdf['TPA-1 Beam'] == low]\n",
    "                discard_rows.append(discard_row)\n",
    "\n",
    "    # Combine rows to discard\n",
    "    if discard_rows:\n",
    "        discard_df = pd.concat(discard_rows)\n",
    "    else:\n",
    "        discard_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    # Step 4: Return cleaned dataframe and discarded rows\n",
    "    df_cleaned = df.drop(index=discard_df.index).reset_index(drop=True)\n",
    "    discard_df = discard_df.reset_index(drop=True)\n",
    "\n",
    "    return df_cleaned, discard_df"
   ],
   "id": "e5ec159586267c22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# usage\n",
    "cleaned, discarded = simplify_uhf_conflicts(df)\n"
   ],
   "id": "27d1eb1bd27e25f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(cleaned)",
   "id": "47c8a7866d08c39b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display(discarded)",
   "id": "3ca08400f37e954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "tpafile = './databases/TPAtable.csv'\n",
    "tablesfolder = 'countriestables'\n",
    "outfolder = 'adm_conflicts'\n",
    "countrieslistfile = 'countrieslist.csv'\n",
    "\n",
    "# Load country codes\n",
    "with open(countrieslistfile, 'r') as f:\n",
    "    countries = f.read().strip().split(', ')\n",
    "# # todo comment this\n",
    "# countries = ['ARG']\n",
    "\n",
    "# === PROCESS EACH COUNTRY ===\n",
    "for ccode in countries:\n",
    "    print(f\"\\n=== Processing {ccode} ===\")\n",
    "\n",
    "    # outfolder (must already exist)\n",
    "    country_outfolder = os.path.join(outfolder, ccode)\n",
    "\n",
    "    # Read data for the 'expanded_combined_tables_conflicts_lettersatnames.csv' file\n",
    "    adm = ccode\n",
    "    file = 'conflicts_summary_condensed.csv'\n",
    "    filepath = os.path.join('.', 'adm_conflicts', adm, file)\n",
    "    df = pd.read_csv(filepath, low_memory=False)\n",
    "\n",
    "    # Generate summary pivot table\n",
    "    summary_pivot, discarded = simplify_uhf_conflicts(df)\n",
    "\n",
    "    # save\n",
    "    outpath = os.path.join(country_outfolder, 'conflicts_summary_condensed_clean.csv')\n",
    "    summary_pivot.to_csv(outpath, index=False)\n",
    "    print('Summary condensed saved to ', outpath)\n",
    "    outpath = os.path.join(country_outfolder, 'conflicts_summary_condensed_redundant.csv')\n",
    "    discarded.to_csv(outpath, index=False)\n",
    "    print('Summary condensed saved to ', outpath)\n",
    "\n",
    "    # Read data for the 'expanded_combined_tables_conflicts_othersatnames.csv' file\n",
    "    file = 'conflicts_summary_condensed_othersatnames.csv'\n",
    "    filepath = os.path.join('.', 'adm_conflicts', adm, file)\n",
    "    df = pd.read_csv(filepath, low_memory=False)\n",
    "\n",
    "    # Generate summary pivot table for other satellite names\n",
    "    summary_pivot_othersatnames, discarded_other = simplify_uhf_conflicts(df)\n",
    "    outpath = os.path.join(country_outfolder, 'conflicts_summary_condensed_clean_othersatnames.csv')\n",
    "    summary_pivot_othersatnames.to_csv(outpath, index=False)\n",
    "    print('Summary condensed for other satellite names saved to ', outpath)\n",
    "    outpath = os.path.join(country_outfolder, 'conflicts_summary_condensed_othersatnames_redundant.csv')\n",
    "    discarded_other.to_csv(outpath, index=False)\n",
    "    print('Summary condensed for other satellite names saved to ', outpath)\n",
    "\n"
   ],
   "id": "354167abc4891e8c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
